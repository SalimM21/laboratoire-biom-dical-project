# laboratoire-biomidical-project
-----

# ü©∫ Syst√®me intelligent de pr√©diction du risque de diab√®te

-----

## Description du projet

Ce projet vise √† d√©velopper un syst√®me intelligent capable de **pr√©dire le risque de d√©velopper le diab√®te** chez un patient. Bas√© sur des crit√®res cliniques cl√©s tels que la glyc√©mie (Glucose), la pression art√©rielle (Blood Pressure), l'√©paisseur du pli cutan√© (Skin Thickness), l'insuline, l'Indice de Masse Corporelle (BMI), la fonction de pr√©disposition g√©n√©tique au diab√®te (Diabetes Pedigree Function) et l'√¢ge, ce syst√®me offre une double fonctionnalit√© :

1.  **Classification des patients** : Cat√©goriser un patient comme pr√©sentant un risque √©lev√© ou faible de diab√®te.
2.  **Clustering des donn√©es** : Regrouper les patients ayant des profils cliniques similaires afin d'identifier des comportements ou des caract√©ristiques communes au sein de la population √©tudi√©e.

L'objectif est de fournir un outil d'aide √† la d√©cision pour les professionnels de la sant√©, permettant une intervention pr√©coce et une gestion proactive du risque de diab√®te.

-----

## üìä M√©thodologie

Le d√©veloppement de ce syst√®me intelligent a suivi une approche structur√©e, englobant l'analyse exploratoire, le pr√©traitement, le clustering et la classification :

### 1\. Chargement et Analyse Exploratoire des Donn√©es (EDA)

  * **Importation** des donn√©es cliniques historiques (format CSV) √† l'aide de Pandas.
  * **Compr√©hension de la structure** du jeu de donn√©es (types de colonnes, dimensions, aper√ßu des premi√®res lignes).
  * **Identification des valeurs manquantes et des doublons**.
  * **Analyse de la distribution** des variables num√©riques via des histogrammes et des bo√Ætes √† moustaches.
  * **√âtude des corr√©lations** entre les variables √† l'aide d'une matrice de corr√©lation et de `pairplots`.

### 2\. Pr√©traitement des Donn√©es

  * **Gestion des valeurs manquantes** : Remplacement des valeurs 0 (repr√©sentant des NaN) dans des colonnes comme 'Glucose', 'BloodPressure', 'BMI', 'Insulin', 'SkinThickness' par la **m√©diane** de leur colonne respective.
  * **D√©tection et suppression des valeurs aberrantes (outliers)** : Utilisation de la m√©thode de l'**IQR (InterQuartile Range)** pour identifier et supprimer les lignes contenant des valeurs extr√™mes dans les colonnes pertinentes, garantissant la robustesse du mod√®le.
  * **S√©lection des variables** : Choix des caract√©ristiques les plus pertinentes pour le clustering et la classification (`Glucose`, `BMI`, `Age`, `DiabetesPedigreeFunction`).
  * **Mise √† l'√©chelle des variables** : Application de `StandardScaler` pour homog√©n√©iser les √©chelles des variables num√©riques, une √©tape cruciale pour la plupart des algorithmes d'apprentissage automatique.

### 3\. Clustering avec K-Means

  * **D√©termination du nombre optimal de clusters (`k`)** : Utilisation de la **m√©thode du coude** (Elbow Method) pour √©valuer l'inertie pour diff√©rentes valeurs de `k` et identifier le point d'inflexion optimal.
  * **Entra√Ænement du mod√®le K-Means** : Cr√©ation des clusters bas√©s sur les donn√©es pr√©trait√©es et mises √† l'√©chelle.
  * **Assignation des clusters** : Ajout d'une colonne `Cluster` au jeu de donn√©es original, indiquant le groupe attribu√© √† chaque patient.
  * **Interpr√©tation des clusters** : Calcul des moyennes des caract√©ristiques pour chaque cluster afin de comprendre les profils de patients.
  * **Cat√©gorisation du risque** : Cr√©ation d'une colonne `risk_category` (`High Risk` / `Low Risk`) bas√©e sur l'interpr√©tation des clusters.

### 4\. R√©duction de Dimensionnalit√© (PCA)

  * **Application de l'Analyse en Composantes Principales (PCA)** : R√©duction des dimensions des donn√©es √† 2 composantes principales (`PC1`, `PC2`) pour faciliter la visualisation.
  * **Visualisation des clusters** : Affichage des clusters dans l'espace 2D de la PCA pour une meilleure compr√©hension de leur r√©partition.

### 5\. Classification des Patients

  * **Pr√©paration des donn√©es** :
      * D√©finition de la variable cible `y` (`risk_category`) et des variables explicatives `X`.
      * **Division des donn√©es** en ensembles d'entra√Ænement (70%) et de test (30%) via `train_test_split`.
      * **Gestion du d√©s√©quilibre des classes** : Utilisation de `RandomOverSampler` sur l'ensemble d'entra√Ænement pour √©quilibrer la r√©partition des cat√©gories de risque.
  * **Entra√Ænement de plusieurs mod√®les de classification** :
      * **Random Forest Classifier**
      * **Support Vector Machine (SVM)**
      * **Gradient Boosting Classifier**
      * **R√©gression Logistique**
  * **√âvaluation des mod√®les** : Utilisation de m√©triques cl√©s pour √©valuer les performances de chaque mod√®le sur l'ensemble de test :
      * **Matrice de confusion**
      * **Rapport de classification** (pr√©cision, rappel, F1-score)
      * **Accuracy**
  * **Validation crois√©e** : √âvaluation de la robustesse des mod√®les sur diff√©rentes partitions du jeu de donn√©es (5-fold cross-validation) pour obtenir une estimation plus fiable de leur performance g√©n√©ralis√©e.
  * **Optimisation des hyperparam√®tres** : Application de `GridSearchCV` pour affiner les hyperparam√®tres des mod√®les `RandomForestClassifier` et `GradientBoostingClassifier`, afin d'am√©liorer leur performance.
  * **S√©lection et sauvegarde du meilleur mod√®le** : Comparaison des performances finales des mod√®les (en privil√©giant le F1-score pour la classification avec d√©s√©quilibre) et sauvegarde du mod√®le le plus performant au format `.pkl` pour un d√©ploiement ult√©rieur.

-----

## üìÅ Structure des fichiers

```
.
‚îú‚îÄ‚îÄ diabete_data.csv
‚îú‚îÄ‚îÄ diabetes_prediction.ipynb
‚îú‚îÄ‚îÄ diabetes_risk_prediction_model.pkl
‚îú‚îÄ‚îÄ scaler.pkl
‚îú‚îÄ‚îÄ app.py                     # NOUVEAU: Votre application Streamlit
‚îú‚îÄ‚îÄ requirements.txt           # NOUVEAU: Vos d√©pendances Python
‚îú‚îÄ‚îÄ Dockerfile                 # NOUVEAU: Les instructions Docker
‚îî‚îÄ‚îÄ README.md
```

-----

## üöÄ Instructions pour l'ex√©cuter

Pour ex√©cuter ce projet sur votre machine locale, suivez les √©tapes ci-dessous :

### 1\. Pr√©requis

Assurez-vous d'avoir Python 3.x install√©. Vous pouvez v√©rifier votre version de Python avec :

```bash
python --version
```

### 2\. Cloner le d√©p√¥t (si applicable)

Si ce projet est sur un d√©p√¥t Git, clonez-le :

```bash
git clone https://github.com/SalimM21/laboratoire-biom-dical-project/tree/main
cd laboratoire-biom-dical-project

```

### 3\. Cr√©er et activer un environnement virtuel (recommand√©)

```bash
python -m venv venv
# Pour Windows
.\venv\Scripts\activate
# Pour macOS/Linux
source venv/bin/activate
```

### 4\. Installer les d√©pendances

Installez toutes les biblioth√®ques n√©cessaires :

```bash
pip install pandas numpy scikit-learn matplotlib seaborn imbalanced-learn joblib
```

### 5\. Ex√©cuter le Notebook Jupyter

Lancez Jupyter Notebook dans le r√©pertoire du projet :

```bash
jupyter notebook
```

Ouvrez le fichier `diabetes_prediction.ipynb` et ex√©cutez toutes les cellules s√©quentiellement. Le notebook contient toutes les √©tapes, du chargement des donn√©es √† l'√©valuation et la sauvegarde du mod√®le.

### 6\. V√©rifier le mod√®le sauvegard√©

Apr√®s l'ex√©cution compl√®te du notebook, un fichier `diabetes_risk_prediction_model.pkl` sera cr√©√© dans le m√™me r√©pertoire, repr√©sentant le mod√®le entra√Æn√© et pr√™t √† l'emploi.

-----
